{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos:518\n",
      "total youtubers:473\n",
      "colums:video_id,title,video_length,publish_at,category_id,category,language,live_content,description,tags,comment_count,view_count,like_count,dislike_count,emb_url,channel_name,subscriber_count,days_on,cel_lvl,vw_ct,cmnt_ct,day_vw,day_cmnt,rel_vw,like_rt,cmnt_rt\n"
     ]
    }
   ],
   "source": [
    "# @author: Niu\n",
    "# convert the teamtrees_network.json to csv file.\n",
    "# One row for each video\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import dateutil\n",
    "import pytz\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime, timezone\n",
    "from datetime import timedelta\n",
    "import dateutil.parser\n",
    "\n",
    "def get_status(sub):\n",
    "    if sub>=1000000:\n",
    "        return \"celebrity\"\n",
    "    elif 10000<=sub<1000000:\n",
    "        return \"professional\"\n",
    "    else:\n",
    "        return \"amateur\"\n",
    "    \n",
    "youtuber_list_path=\"KEY/teamtrees_network.json\"\n",
    "\n",
    "def get_video_days(day_str):\n",
    "    video_date = dateutil.parser.parse(day_str)\n",
    "    crawl_date=datetime(2020, 1, 8, tzinfo=timezone.utc)\n",
    "    delta = crawl_date - video_date\n",
    "    return delta.days\n",
    "\n",
    "data=[]\n",
    "with open(youtuber_list_path,'r') as fp:\n",
    "    youtubers=json.loads(fp.read())[\"nodes\"]\n",
    "    for you in youtubers:\n",
    "        channel_name=you[\"channel_name\"]\n",
    "        for video in you[\"video_list\"]:\n",
    "            del video[\"caption\"]\n",
    "            del video[\"comment_list\"]\n",
    "            video[\"emb_url\"]=\"https://www.youtube.com/embed/\"+video[\"video_id\"]+\"?autoplay=0\"\n",
    "            video[\"channel_name\"]=channel_name\n",
    "            video[\"tags\"]=\",\".join([\"\\\"\"+t+\"\\\"\" for t in video[\"tags\"]])\n",
    "            video[\"subscriber_count\"]=you[\"subscriber_count\"]\n",
    "            date1=dateutil.parser.isoparse(video[\"publish_at\"])\n",
    "            date2=dateutil.parser.isoparse(\"2020-01-08T00:00:00.000Z\")\n",
    "            video[\"days_on\"]=(date2-date1).days\n",
    "            video[\"cel_lvl\"]=get_status(you[\"subscriber_count\"])\n",
    "            video[\"vw_ct\"]=video[\"view_count\"]           \n",
    "            video[\"cmnt_ct\"]=video[\"comment_count\"]\n",
    "            video[\"day_vw\"]=video[\"view_count\"]  /get_video_days(video[\"publish_at\"])         \n",
    "            video[\"day_cmnt\"]=video[\"comment_count\"] /get_video_days(video[\"publish_at\"])\n",
    "            video[\"rel_vw\"]=video[\"view_count\"]*you[\"video_count\"]/you[\"view_count\"]\n",
    "            video[\"like_rt\"]=(video[\"like_count\"]-video[\"dislike_count\"])*100/(video[\"view_count\"]+1)\n",
    "            video[\"cmnt_rt\"]=video[\"comment_count\"]*100/(video[\"view_count\"]+1)\n",
    "            data.append(video)\n",
    "            \n",
    "        \n",
    "youtuber_save_path=\"KEY/video_meta_data.csv\"\n",
    "with open(youtuber_save_path, mode='w+', encoding=\"utf-8\", newline='') as fp:\n",
    "    csv_writer = csv.writer(fp, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    first = True\n",
    "    for v in data:\n",
    "        if first:\n",
    "            csv_writer.writerow([key for key, value in v.items()])\n",
    "            first = False\n",
    "        csv_writer.writerow([value for key, value in v.items()])\n",
    "        \n",
    "print(f\"total videos:{len(data)}\")\n",
    "print(f\"total youtubers:{len(youtubers)}\")\n",
    "print(f\"colums:{','.join(data[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total accepted: 470\n",
      "total processed: 470\n",
      "total accepted: 470\n",
      "It works I guess\n"
     ]
    }
   ],
   "source": [
    "#@author Mai\n",
    "#@version: 2/27/20\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import statistics\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "result_path = \"./KEY/\"\n",
    "directory=\"./data_tagging_j8\"\n",
    "\n",
    "data = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        with open(directory+\"/\"+filename, mode = \"r+\", encoding=\"utf-8\") as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            for row in csv_reader:\n",
    "                data.append(row)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "wrong_data=[]\n",
    "with open(result_path + \"broken_data.csv\", encoding=\"utf-8\") as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        wrong_data.append(row)\n",
    "\n",
    "wrong_data=[d[\"video_url\"] for d in wrong_data]\n",
    "ok = [d for d in data\n",
    "      if d[\"STATUS\"] == \"OK\" and d[\"VIDEO_URL\"] not in wrong_data]\n",
    "\n",
    "url_dict = defaultdict(list)\n",
    "for d in ok:\n",
    "    url_dict[d[\"VIDEO_URL\"]].append(d)\n",
    "    \n",
    "manual_tag =[]\n",
    "with open(result_path + \"final_tag.csv\", encoding=\"utf-8\") as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        manual_tag.append(row)\n",
    "manual_tag = [(d[\"VIDEO_URL\"], d[\"final_tagging\"]) for d in manual_tag]   \n",
    "print(f\"total accepted: {len(url_dict)}\")\n",
    "\n",
    "def convert_rating(mylist, tag):\n",
    "    rating = [d[tag] for d in mylist]\n",
    "    total = []\n",
    "    for i in range(len(rating)):\n",
    "        if rating[i] == \"very_high\": total.append(5)\n",
    "        elif rating[i] == \"high\":    total.append(4)\n",
    "        elif rating[i] == \"neutral\": total.append(3)\n",
    "        elif rating[i] == \"low\":     total.append(2)\n",
    "        elif rating[i] == \"very_low\": total.append(1)    \n",
    "    avg = statistics.mean(total)\n",
    "    return avg\n",
    "\n",
    "creation = [\"theme_creation_object\", \"theme_creation_performance\", \"knowledge\"]\n",
    "participation = [\"planting_trees\", \"donating\"]\n",
    "connection_comment = [\"spread_word\", \"comment_news\", \"live_stream_stat\", \"comment_video\", \"live_stream_game\"]\n",
    "\n",
    "def merge_cat(cat):\n",
    "    \n",
    "    category = \"Other\" #not_recognized\n",
    "    \n",
    "    if (cat in creation):\n",
    "        category = \"Creation\"\n",
    "    elif (cat in participation):\n",
    "        category = \"Participation\"\n",
    "    elif (cat in connection_comment):\n",
    "        category = \"Connection\"\n",
    "    return category\n",
    "\n",
    "def isMentioned(mylist, tag):\n",
    "    count_cat = sum([float(d[tag]) for d in mylist])\n",
    "    if (count_cat >= MAJORITY):\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "url_temp = {}\n",
    "rejected_url = []\n",
    "URL_COUNT = 3 #number of acceptable tasks per link\n",
    "MAJORITY = math.ceil(URL_COUNT/2)\n",
    "celeb_name = [\"mrbeast\", \"arborday\", \"teamtrees_org\",\"noteble_youtuber\",\"noteble_entrepreneur\"]\n",
    "\n",
    "for url, l in url_dict.items():\n",
    "    category = [c[\"category\"] for c in l]\n",
    "    is_unique = len(set(category)) == len(category) #converts list to set to check if they're unique\n",
    "    if (is_unique):\n",
    "        for tup in manual_tag:\n",
    "            if (tup[0] == url):\n",
    "                cat = tup[1]\n",
    "    else:\n",
    "        cat = (Counter(category).most_common(1)[0])[0]\n",
    "    \n",
    "    url_temp[url] = {\n",
    "        \"VIDEO_URL\": l[0][\"VIDEO_URL\"],\n",
    "        \"style\": cat,\n",
    "        \"part_act\" : merge_cat(cat),\n",
    "        \"quality\": convert_rating(l, \"quality\"),\n",
    "        \"creativity\": convert_rating(l, \"creativity\"),\n",
    "        \"awareness\": convert_rating(l, \"awareness\")\n",
    "    }\n",
    "    mention_count = 0\n",
    "    for name in celeb_name:\n",
    "        is_mentioned = isMentioned(l,name)\n",
    "        url_temp[url][name] = \"y\" if is_mentioned == 1 else \"n\" \n",
    "        mention_count+= is_mentioned\n",
    "    url_temp[url][\"mention_count\"] = mention_count    \n",
    "\n",
    "print(f\"total processed: {len(url_dict)}\")\n",
    "print(f\"total accepted: {len(url_temp)}\")\n",
    "\n",
    "try:\n",
    "   os.mkdir(result_path)\n",
    "except OSError as e:\n",
    "   print(\"It works I guess\")\n",
    "\n",
    "with open(result_path + \"final_accepted_taggings.csv\", mode='w', encoding=\"utf-8\") as csv_result:\n",
    "    csv_writer = csv.writer(csv_result,\n",
    "                            delimiter = \",\",\n",
    "                            quotechar = '\"',\n",
    "                            quoting = csv.QUOTE_MINIMAL,\n",
    "                           lineterminator = \"\\n\")\n",
    "    isFirst=True\n",
    "    for v in url_temp.values():\n",
    "        if isFirst:\n",
    "            csv_writer.writerow(v.keys())\n",
    "            isFirst=False\n",
    "        csv_writer.writerow(v.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos: 518\n",
      "total wrong data: 48\n",
      "total accepted: 470\n",
      "total final data in meta: 470\n"
     ]
    }
   ],
   "source": [
    "#@version: 2/18/20\n",
    "\n",
    "import csv \n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "result_path = \"./KEY/\"\n",
    "\n",
    "data = []\n",
    "wrong_data=[]\n",
    "with open(result_path + \"video_meta_data.csv\",\"r+\", encoding=\"utf-8\") as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "        \n",
    "print(f\"total videos: {len(data)}\")\n",
    "\n",
    "with open(result_path + \"broken_data.csv\", encoding=\"utf-8\") as fp:\n",
    "    csv_reader = csv.DictReader(fp)\n",
    "    for row in csv_reader:\n",
    "        wrong_data.append(row)\n",
    "\n",
    "wrong_data=[d[\"video_url\"] for d in wrong_data]\n",
    "data = [d for d in data if d[\"emb_url\"] not in wrong_data]\n",
    "print(f\"total wrong data: {len(wrong_data)}\")\n",
    "\n",
    "url_dict = defaultdict(list)\n",
    "for d in data:\n",
    "    url_dict[d[\"emb_url\"]].append(d)\n",
    "\n",
    "# print(url_dict)\n",
    "\n",
    "accepted_data = []\n",
    "with open(result_path + \"final_accepted_taggings.csv\",\"r+\", encoding=\"utf-8\") as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        accepted_data.append(row)\n",
    "#print(accepted_data[0].items())\n",
    "#print(accepted_data)\n",
    "#print(list(accepted_data[0].items())[0:3])\n",
    "\n",
    "accepted_url = [d[\"VIDEO_URL\"] for d in accepted_data]\n",
    "print(f\"total accepted: {len(accepted_url)}\")\n",
    "\n",
    "\n",
    "for url in url_dict:\n",
    "    list_temp = []\n",
    "    for d in accepted_data:\n",
    "        #print(d.items())\n",
    "        if (d[\"VIDEO_URL\"] == url):\n",
    "            list_temp = [tup for tup in d.items() if tup[0] != \"VIDEO_URL\"]                \n",
    "            break\n",
    "    for i in range(len(list_temp)):\n",
    "            url_dict[url][0][list_temp[i][0]]= list_temp[i][1] \n",
    "#print(json.dumps(data, indent = 2))\n",
    "print(f\"total final data in meta: {len(url_dict)}\")\n",
    "#print(url_dict)\n",
    "\n",
    "with open(result_path + \"final_meta_all.csv\", mode='w', encoding=\"utf-8\") as csv_result:\n",
    "    csv_writer = csv.writer(csv_result,\n",
    "                            delimiter = \",\",\n",
    "                            quotechar = '\"',\n",
    "                            quoting = csv.QUOTE_MINIMAL,\n",
    "                            lineterminator = \"\\n\")\n",
    "\n",
    "    isFirst = True\n",
    "    for i in url_dict.keys():\n",
    "        if isFirst:\n",
    "            header = list(url_dict[i][0])\n",
    "            csv_writer.writerow(header)\n",
    "            isFirst = False\n",
    "        csv_writer.writerow(url_dict[i][0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result_path = \"./KEY/\"\n",
    "\n",
    "df=pd.read_csv(result_path+\"final_meta_all.csv\")\n",
    "df=df.loc[df.part_act!=\"Other\"]\n",
    "statues=list(df[\"cel_lvl\"].unique())\n",
    "styles=list(df[\"style\"].unique())\n",
    "for index, row in df.iterrows():\n",
    "    for st in statues:\n",
    "        if st==row[\"cel_lvl\"]:\n",
    "            df.loc[index, st]=\"y\"\n",
    "        else:\n",
    "            df.loc[index,st]=\"n\"\n",
    "    for sl in styles:\n",
    "        if sl==row[\"style\"]:\n",
    "            df.loc[index, sl]=\"y\"\n",
    "        else:\n",
    "            df.loc[index,sl]=\"n\"\n",
    "df.to_csv(result_path+\"final_meta_all_processed - no other + dummy.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
