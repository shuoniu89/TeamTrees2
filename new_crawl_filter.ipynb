{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2.dev\n"
     ]
    }
   ],
   "source": [
    "import clarku_youtube_crawler as cu\n",
    "import pandas as pd\n",
    "\n",
    "print(cu.__version__)\n",
    "#time to check config.ini\n",
    "\n",
    "# cu.config_override(True) #generally not needed unless you want completely new workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2.dev\n",
      "Directory already exists YouTube_RAW_20210113/\n",
      "Directory already exists YouTube_RAW_20210113//video_list/\n",
      "Directory already exists YouTube_RAW_20210113//video_data/\n",
      "Update Developer Key:AIzaSyDSXNG8zCEsWMIdyx8ZutPGIo_MEsN1kK4\n",
      "BUILD SUCCESS\n",
      "Directory already exists YouTube_RAW_20210113//video_list/baduk\n",
      "start crawling:10-25-2019\n",
      "crawling video list....\n",
      "total results:14212 between 10-25-2019 and 10-26-2019\n",
      "start crawling:10-26-2019\n",
      "crawling video list....\n",
      "total results:15333 between 10-26-2019 and 10-27-2019\n",
      "start crawling:10-27-2019\n",
      "crawling video list....\n",
      "total results:15351 between 10-27-2019 and 10-28-2019\n",
      "crawling baduk data from YouTube_RAW_20210113//video_list.csv....\n",
      "Crawling baduk (0/33): FH1MZbGumNM.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): PBqnJ0ghXi4.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): Rr299m3CZ_U.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): vWs_bBMsOdQ.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): kRtBI2jY4ow.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): Uqhy31W8dVg.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): hkfAnAmz_gk.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): c3qDf9P9wnc.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): YL-u6LLky0s.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): JKTA5uBU3oo.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): d3TexRieblI.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): tgLXotmPPjo.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): rVGFY2oN0gs.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): 0CNeFg19zEE.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): yKbHY3VfxWg.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): 3YjggcXSHXw.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): vdozDkooUlE.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): Yr0e3eEsUJU.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): EStLpWnC3uM.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): 4Yxj-dgv71U.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): TZrnZo7xYJI.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): yIJXHiSsDNk.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): xpysZI4su6Y.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): yoGaKhKAL_w.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): 1IHWZebCjFg.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): LZpKkysrlPM.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): AqCA7P_5jsI.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): D7P5cRVcTgI.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): DmBbIfQAHDc.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): 7mYERlsD_P8.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): jrigq0Dc3_4.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): ERU0fME3fK8.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Crawling baduk (0/33): 83ybBJW6b28.json\n",
      "Already crawled in YouTube_RAW_20210113//video_data/\n",
      "Merging to YouTube_RAW_20210113//FINAL_merged_baduk.json\n",
      "Directory already exists YouTube_CSV/\n",
      "Saved files to YouTube_CSV/\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "print(cu.__version__)\n",
    "\n",
    "raw_crawler = cu.RawCrawler()\n",
    "raw_crawler.__build__()\n",
    "\n",
    "start_month = 10\n",
    "start_day = 25\n",
    "start_year = 2019\n",
    "end_month = 12\n",
    "end_day = 31\n",
    "end_year = 2019\n",
    "\n",
    "start = date(start_year, start_month, start_day)\n",
    "end = date(end_year, end_month, end_day)\n",
    "delta = end-start\n",
    "\n",
    "raw_crawler.crawl(\"baduk\",\n",
    "                  start_day=start_day,\n",
    "                  start_month=start_month,\n",
    "                  start_year=start_year,\n",
    "                  day_count=3)\n",
    "#\n",
    "raw_crawler.crawl_videos_in_list(search_key=\"baduk\")\n",
    "raw_crawler.merge_all(mode=\"sep\",\n",
    "                      search_key=[\"baduk\"]\n",
    "                      )\n",
    "\n",
    "\n",
    "decoder=cu.JSONDecoder()\n",
    "decoder.load_json(\"YouTube_RAW_20210113/FINAL_merged_baduk.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "len(os.listdir(\"YouTube_RAW_20210111/video_data/teamtrees\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602\n",
      "1087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def isEnglish(s):\n",
    "    s=deEmojify(s)\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "df = pd.read_csv(\"YouTube_CSV/video_FINAL_merged_teamtrees.csv\")\n",
    "df.fillna(\"\", inplace=True)\n",
    "non_english = [row[\"videoId\"] for index,row in df.iterrows() if not isEnglish(row[\"title\"]) or not isEnglish(row[\"description\"])]\n",
    "            \n",
    "print(len(non_english)) #602\n",
    "df_english = df[~df[\"videoId\"].isin(non_english)]\n",
    "print(len(df_english))\n",
    "\n",
    "df_snowtagged = pd.read_csv(\"snowtagged.csv\")\n",
    "snow_id = [url.replace(\"https://www.youtube.com/watch?v=\",\"\") for url in df_snowtagged.video_url]\n",
    "df_id = [vidid.replace(\":\",\"\") for vidid in df.videoId]\n",
    "same = [vidid for vidid in snow_id if vidid in df_id]\n",
    "len(same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "df_old = pd.read_csv(\"FINAL_DATA.csv\")\n",
    "df_old.fillna(\"\", inplace=True)\n",
    "old_id = list(df_old.video_id)\n",
    "# diff = [vidid for vidid in old_id if vidid not in list(df.videoId)]\n",
    "\n",
    "# english_old = [row[\"video_id\"] for index,row in df_old.iterrows() if isEnglish(row[\"title\"]) and isEnglish(row[\"description\"])]\n",
    "non_english_old = [row[\"video_id\"] for index,row in df_old.iterrows() if not isEnglish(row[\"title\"]) or not isEnglish(row[\"description\"])]\n",
    "\n",
    "\n",
    "# diff = [vidid for vidid in english_old if vidid not in list(df.videoId)]\n",
    "# len(diff)\n",
    "english_lang = []\n",
    "# for id in non_english_old:\n",
    "#     description = str(df_old.loc[df_old.video_id==id].description.astype('str'))\n",
    "#     if detect(description):\n",
    "#         english_lang.append(id)\n",
    "#         continue\n",
    "#     if detect(str(df_old.loc[df_old.video_id==id].title)):\n",
    "#         english_lang.append(id)\n",
    "for index, row in df_old.iterrows():\n",
    "    if row[\"video_id\"] not in non_english_old:\n",
    "        continue\n",
    "    if detect(row[\"description\"]):\n",
    "        english_lang.append(row[\"video_id\"])\n",
    "        continue\n",
    "    if detect(row[\"title\"]):\n",
    "        english_lang.append(row[\"video_id\"])\n",
    "\n",
    "len(english_lang)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
