{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file reads the raw file in and filter all non-english videos and videos published in countries other than \"US\", \"CA\", \"GB\", \"AU\", \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cat Mai\\anaconda3\\lib\\site-packages\\nltk\\decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "C:\\Users\\Cat Mai\\anaconda3\\lib\\site-packages\\nltk\\lm\\counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence, defaultdict\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Cat\n",
      "[nltk_data]     Mai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect\n",
    "from pprint import pprint\n",
    "import math\n",
    "import os \n",
    "from scipy.stats import sem\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models import Phrases\n",
    "from gensim import corpora, models\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.test.utils import datapath\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: DeprecationWarning: invalid escape sequence \\.\n",
      "<>:26: DeprecationWarning: invalid escape sequence \\.\n",
      "<>:26: DeprecationWarning: invalid escape sequence \\.\n",
      "<ipython-input-10-8cc8a1b13507>:26: DeprecationWarning: invalid escape sequence \\.\n",
      "  result=re.sub('[,\\.!?]', '', str(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445\n",
      "1138\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:--_dsS5AFFw</td>\n",
       "      <td>does santa claus | christmas song special #tea...</td>\n",
       "      <td>[santa, claus, christmas, song, special, teamt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:-5VBe9i4HDg</td>\n",
       "      <td>live tree planting counter - teamtrees [20 mil...</td>\n",
       "      <td>[live, tree, plant, counter, teamtrees, millio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:-665K6Mu6os</td>\n",
       "      <td>the moment when rak donated $100000 to #teamtr...</td>\n",
       "      <td>[moment, rak, donate, 100000, teamtrees, momen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:-99jZt79aWk</td>\n",
       "      <td>why are trees so awesome #teamtrees nanodots m...</td>\n",
       "      <td>[tree, awesome, teamtrees, nanodots, magnets, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:-BqH2PKqFpM</td>\n",
       "      <td>the tree face #teamtrees robisplays teamtrees ...</td>\n",
       "      <td>[tree, face, teamtrees, robisplays, teamtrees,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>:_vQ7OeVWBrU</td>\n",
       "      <td>let's stream for teamtrees gaming pixelfire ai...</td>\n",
       "      <td>[let, stream, teamtrees, game, pixelfire, code...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>:_Xw9Av0mCcc</td>\n",
       "      <td>mrbeast plants 10 million trees - #teamtrees -...</td>\n",
       "      <td>[mrbeast, plant, million, tree, teamtrees, liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>:_yKFJm75qO0</td>\n",
       "      <td>planting 20 million trees in prison architect ...</td>\n",
       "      <td>[plant, million, tree, prison, architect, simu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>:_zT8aOvNLaY</td>\n",
       "      <td>asmr | bob ross inspired painting asmr for #te...</td>\n",
       "      <td>[asmr, bob, ross, inspire, paint, asmr, teamtr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>:__8RrX7Z8iY</td>\n",
       "      <td>reducing noise with indow #teamtrees &amp; lumber ...</td>\n",
       "      <td>[reduce, noise, indow, teamtrees, lumber, jack...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1138 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           videoId                                               text  \\\n",
       "0     :--_dsS5AFFw  does santa claus | christmas song special #tea...   \n",
       "1     :-5VBe9i4HDg  live tree planting counter - teamtrees [20 mil...   \n",
       "2     :-665K6Mu6os  the moment when rak donated $100000 to #teamtr...   \n",
       "3     :-99jZt79aWk  why are trees so awesome #teamtrees nanodots m...   \n",
       "4     :-BqH2PKqFpM  the tree face #teamtrees robisplays teamtrees ...   \n",
       "...            ...                                                ...   \n",
       "1439  :_vQ7OeVWBrU  let's stream for teamtrees gaming pixelfire ai...   \n",
       "1441  :_Xw9Av0mCcc  mrbeast plants 10 million trees - #teamtrees -...   \n",
       "1442  :_yKFJm75qO0  planting 20 million trees in prison architect ...   \n",
       "1443  :_zT8aOvNLaY  asmr | bob ross inspired painting asmr for #te...   \n",
       "1444  :__8RrX7Z8iY  reducing noise with indow #teamtrees & lumber ...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [santa, claus, christmas, song, special, teamt...  \n",
       "1     [live, tree, plant, counter, teamtrees, millio...  \n",
       "2     [moment, rak, donate, 100000, teamtrees, momen...  \n",
       "3     [tree, awesome, teamtrees, nanodots, magnets, ...  \n",
       "4     [tree, face, teamtrees, robisplays, teamtrees,...  \n",
       "...                                                 ...  \n",
       "1439  [let, stream, teamtrees, game, pixelfire, code...  \n",
       "1441  [mrbeast, plant, million, tree, teamtrees, liv...  \n",
       "1442  [plant, million, tree, prison, architect, simu...  \n",
       "1443  [asmr, bob, ross, inspire, paint, asmr, teamtr...  \n",
       "1444  [reduce, noise, indow, teamtrees, lumber, jack...  \n",
       "\n",
       "[1138 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gen tokens for each video. merge title and tags\n",
    "# Filter the data and generate token lists\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def isEnglish(s):\n",
    "    s=deEmojify(s)\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def process_text(txt):\n",
    "    result=str(txt)\n",
    "    soup = BeautifulSoup(result)\n",
    "    result=soup.get_text()\n",
    "    result=re.sub('[,\\.!?]', '', str(result))\n",
    "    result=result.lower()\n",
    "    return result\n",
    "\n",
    "def process_tag(tags):\n",
    "    result = tags.strip('][').split(',') \n",
    "    result=[r.strip('\\' ') for r in result]\n",
    "    result=\" \".join(result)\n",
    "    return result\n",
    "\n",
    "def lemmatize_stemming(tokens):\n",
    "    tks=[t.lower() for t in tokens if len(t)>=3]\n",
    "    result=filter(lambda t: t not in STOPWORDS, tks)\n",
    "    result=[lemmatizer.lemmatize(tk, pos='v') for tk in result]\n",
    "#     result=[stemmer.stem(tk) for tk in result]\n",
    "    return result\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"YouTube_CSV/video_FINAL_merged_teamtrees.csv\")\n",
    "print(len(df))    \n",
    "sdf=df.loc[df.country.isin([\"US\", \"CA\", \"GB\", \"AU\", \"unknown\"])]# only in English speaking countries\n",
    "# sdf=df.loc[df.country.isin([\"US\", \"CA\", \"GB\", \"AU\", \"unknown\"])].iloc[:5000,:]# only in English speaking countries\n",
    "texts=sdf.title.apply(process_text)\n",
    "tags=sdf.tags.apply(process_tag)\n",
    "corpus=[(text+\" \"+tag) for text,tag in zip(texts, tags)]\n",
    "corpus_df=pd.DataFrame(data={\"videoId\":sdf[\"videoId\"],\"text\":corpus})\n",
    "corpus_df=corpus_df.loc[corpus_df.text.apply(isEnglish)] # must by English\n",
    "corpus_df=corpus_df.loc[corpus_df.text.apply(lambda x: \"teamtrees\" in x.lower())] # must have asmr\n",
    "\n",
    "corpus_df[\"tokens\"]=corpus_df.text.apply(word_tokenize)\n",
    "corpus_df[\"tokens\"]=corpus_df.tokens.apply(lemmatize_stemming) # lower the token and lemmatize\n",
    "bigram = Phrases(corpus_df.tokens, min_count=len(corpus_df)*0.05, delimiter=b'_')\n",
    "corpus_df[\"tokens\"]=corpus_df.tokens.apply(lambda tk: bigram[tk])\n",
    "\n",
    "# Save the dictionary\n",
    "dictionary = gensim.corpora.Dictionary(corpus_df[\"tokens\"])\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "dictionary.save(\"dictionary\")\n",
    "bow=list(corpus_df.tokens.apply(lambda tks:dictionary.doc2bow(tks)))\n",
    "\n",
    "corpus_df.to_csv(\"YouTube_CSV/corpus_data.csv\", index=False)\n",
    "\n",
    "print(len(corpus_df))\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tfidf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-17e6ff51731d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorpus_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tfidf'"
     ]
    }
   ],
   "source": [
    "corpus_df.tfidf.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
